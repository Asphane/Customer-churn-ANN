# ğŸš€ Customer Churn Prediction using Artificial Neural Network (ANN)

An **end-to-end Machine Learning project** that predicts whether a customer is likely to leave a bank using an **Artificial Neural Network (ANN)**.  
This project covers **data preprocessing, model building, evaluation, and deployment** â€” all wrapped into a clean and interactive **Streamlit web application**.

---

## ğŸ¯ Project Objective

Customer churn directly impacts business revenue.  
The goal of this project is to **identify customers who are likely to churn** so that proactive retention strategies can be applied.

This system takes customer attributes as input and outputs a **churn probability** using a trained ANN model.

---

## ğŸ§  What This Project Covers

### ğŸ”¹ Data Preprocessing
- Loaded the `Churn_Modelling.csv` dataset
- Removed non-predictive columns:
  - `RowNumber`
  - `CustomerId`
  - `Surname`
- Encoded categorical features:
  - `Gender` â†’ Label Encoding
  - `Geography` â†’ One-Hot Encoding (France, Germany, Spain)
- Applied **Standard Scaling** to numerical features
- Saved all preprocessing objects for production use:
  - `scaler.pkl`
  - `label_encoder_gender.pkl`
  - `one_hot_encoder_geography.pkl`

---

### ğŸ”¹ Model Architecture (Artificial Neural Network)

A **Sequential ANN** built using TensorFlow / Keras:

- **Input Layer:** 12 neurons (matching encoded feature count)
- **Hidden Layer 1:** 64 neurons, ReLU activation
- **Hidden Layer 2:** 32 neurons, ReLU activation
- **Output Layer:** 1 neuron, Sigmoid activation (churn probability)

---

### ğŸ”¹ Training & Optimization

- **Optimizer:** Adam (learning rate = 0.01)
- **Loss Function:** Binary Crossentropy
- **Callbacks Used:**
  - Early Stopping (monitored `val_loss`)
  - TensorBoard for training visualization
- Prevented overfitting by restoring the **best model weights**

---

## ğŸ“Š Model Performance

| Metric | Value |
|------|------|
| Training Accuracy | ~88.27% |
| Validation Accuracy | ~85% â€“ 86% |
| Training Loss | ~0.279 |
| Validation Loss | ~0.403 |

### ğŸ” Performance Insight
- Strong generalization performance
- Very small gap (â‰ˆ2â€“3%) between training and validation accuracy
- Early Stopping effectively controlled overfitting

---

## ğŸŒ Deployment (Streamlit Web App)

The trained ANN model is deployed using **Streamlit**, allowing:

- Real-time churn prediction
- User-friendly input interface
- Consistent preprocessing using saved encoders & scaler
- Instant probability-based prediction output

ğŸ“ Deployment file:
```
app.py
```

---

## ğŸ“ Project Structure

```

Customer-Churn-Prediction/
â”‚
â”œâ”€â”€ main.ipynb                         # Model training & evaluation
â”œâ”€â”€ app.py                             # Streamlit deployment app
â”œâ”€â”€ Churn_Modelling.csv                # Dataset
â”‚
â”œâ”€â”€ model.h5                           # Trained ANN model
â”œâ”€â”€ scaler.pkl                         # StandardScaler
â”œâ”€â”€ label_encoder_gender.pkl           # Gender encoder
â”œâ”€â”€ one_hot_encoder_geography.pkl      # Geography encoder
â”‚
â””â”€â”€ logs/                              # TensorBoard logs

```

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Install Dependencies
```bash
pip install tensorflow scikit-learn pandas numpy streamlit matplotlib
````

### 2ï¸âƒ£ Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ† Key Highlights

* End-to-end ML pipeline
* Production-ready preprocessing
* ANN-based binary classification
* Overfitting control with Early Stopping
* Real-time deployment using Streamlit
* Clean and modular project structure

---

## ğŸ”® Future Improvements

* Hyperparameter tuning
* Class imbalance handling (SMOTE)
* Feature importance analysis
* Model comparison with XGBoost / Random Forest
* Cloud deployment (AWS / GCP)

---

## â­ Final Note

This project demonstrates a **complete real-world ML workflow** â€” from raw data to deployment.
If you find this useful, consider **starring â­ the repository**!

Happy Learning & Predicting! ğŸ§ âœ¨

```
```
